{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2200dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasted https://github.com/elastic/ember.git into git hub desktop\n",
    "# that created clone under C:\\Users\\Moriah\\Documents\\GitHub\\ember\n",
    "# opened admin cmd\n",
    "## python -m pip install --upgrade pip\n",
    "## cd C:\\Users\\Moriah\\Documents\\GitHub\\ember\n",
    "## python -m pip install -r requirements.txt\n",
    "## python setup.py install\n",
    "## conda config --add channels conda-forge\n",
    "## conda install --file requirements_conda.txt\n",
    "## python setup.py install\n",
    "\n",
    "# wont let me import ember on notebook so tried again\n",
    "# added Anaconda 3 to system path, removed python from user path\n",
    "# python -m pip install --upgrade --global http.sslVerify false\n",
    "# that didnt work. changed sytem path to point to other version on anaconda3\n",
    "# on admin cmd: python setup.py install # unsure if that worked\n",
    "# on notebook: pip install ember # seemed like it worked\n",
    "# import ember # error because missing lief\n",
    "# pip install lief\n",
    " #import ember # no errors this time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e5f3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #data manipulation\n",
    "import pandas as pd #data manipulation\n",
    "import sklearn as sk #modeling & metrics\n",
    "import seaborn as sns #visualizations\n",
    "import scipy as stats #visualizations\n",
    "from matplotlib import pyplot as plt #visualizations\n",
    "\n",
    "#imputation, scaling, metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score, classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#outlier classification\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import xgboost as xgb #xgb model\n",
    "import lightgbm as lgb #lgbm model\n",
    "import re #fix error for lgbm\n",
    "import hyperopt #hyperparameter tuning\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "\n",
    "import shap #shap plot\n",
    "\n",
    "import pickle \n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import gensim\n",
    "import string   \n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "408ca6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 benign, 1 malicious, -1 unlabled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd929328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
      "WARNING:   lief version 0.11.5-551ede5 found instead. There may be slight inconsistencies\n",
      "WARNING:   in the feature calculations.\n",
      "Vectorizing training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 800000/800000 [14:39<00:00, 910.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 200000/200000 [03:32<00:00, 942.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha256</th>\n",
       "      <th>appeared</th>\n",
       "      <th>label</th>\n",
       "      <th>avclass</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
       "      <td>2006-12</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
       "      <td>2007-01</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eac8ddb4970f8af985742973d6f0e06902d42a3684d791...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
       "      <td>2007-02</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>e033bc4967ce64bbb5cafdb234372099395185a6e0280c...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>1</td>\n",
       "      <td>zbot</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>c7d16736fd905f5fbe4530670b1fe787eb12ee86536380...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>1</td>\n",
       "      <td>flystudio</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0020077cb673729209d88b603bddf56b925b18e682892a...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>1b7e7c8febabf70d1c17fe3c7abf80f33003581c380f28...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>836063f2312b597632bca1f738e68e4d23f672d587a7fc...</td>\n",
       "      <td>2018-12</td>\n",
       "      <td>1</td>\n",
       "      <td>emotet</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sha256 appeared  label  \\\n",
       "0       0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12      0   \n",
       "1       c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01      0   \n",
       "2       eac8ddb4970f8af985742973d6f0e06902d42a3684d791...  2007-02      0   \n",
       "3       7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02      0   \n",
       "4       ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02      0   \n",
       "...                                                   ...      ...    ...   \n",
       "999995  e033bc4967ce64bbb5cafdb234372099395185a6e0280c...  2018-12      1   \n",
       "999996  c7d16736fd905f5fbe4530670b1fe787eb12ee86536380...  2018-12      1   \n",
       "999997  0020077cb673729209d88b603bddf56b925b18e682892a...  2018-12      0   \n",
       "999998  1b7e7c8febabf70d1c17fe3c7abf80f33003581c380f28...  2018-12      0   \n",
       "999999  836063f2312b597632bca1f738e68e4d23f672d587a7fc...  2018-12      1   \n",
       "\n",
       "          avclass subset  \n",
       "0                  train  \n",
       "1                  train  \n",
       "2                  train  \n",
       "3                  train  \n",
       "4                  train  \n",
       "...           ...    ...  \n",
       "999995       zbot   test  \n",
       "999996  flystudio   test  \n",
       "999997              test  \n",
       "999998              test  \n",
       "999999     emotet   test  \n",
       "\n",
       "[1000000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ember.create_vectorized_features(\"C:/Users/Moriah/Documents/WorkRelated/HackTheMachine/Ember/\")\n",
    "ember.create_metadata(\"C:/Users/Moriah/Documents/WorkRelated/HackTheMachine/Ember/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb735b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
      "WARNING:   lief version 0.11.5-551ede5 found instead. There may be slight inconsistencies\n",
      "WARNING:   in the feature calculations.\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"C:/Users/Moriah/Documents/WorkRelated/HackTheMachine/Ember/\")\n",
    "metadata_dataframe = ember.read_metadata(\"C:/Users/Moriah/Documents/WorkRelated/HackTheMachine/Ember/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb599b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 2381)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6a3ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01467612 0.00422187 0.00392268 ... 0.00392365 0.00406099 0.00720765]\n",
      " [0.18452372 0.0313075  0.00569281 ... 0.00427506 0.00362468 0.05886342]\n",
      " [0.25173673 0.01420455 0.00684149 ... 0.00054932 0.00357888 0.07585005]\n",
      " [0.00896443 0.00405471 0.00392475 ... 0.00385578 0.00382844 0.00521506]\n",
      " [0.02040114 0.00521317 0.00451895 ... 0.00376059 0.00389233 0.00546798]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5,:256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa0f1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
      "WARNING:   lief version 0.11.5-551ede5 found instead. There may be slight inconsistencies\n",
      "WARNING:   in the feature calculations.\n",
      "[LightGBM] [Info] Number of positive: 300000, number of negative: 300000\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 14.455858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 212057\n",
      "[LightGBM] [Info] Number of data points in the train set: 600000, number of used features: 2333\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = ember.train_model(r\"C:/Users/Moriah/Documents/WorkRelated/HackTheMachine/Ember/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "476a81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model2 = lgb.Booster(model_file=\"C:/Users/Moriah/Documents/WorkRelated/HackTheMachine/Ember/ember_model_2018.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8ccc609",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/putty.exe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10892/1093043560.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mputty_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"~/putty.exe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0member\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgbm_model2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mputty_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/putty.exe'"
     ]
    }
   ],
   "source": [
    "putty_data = open(\"~/putty.exe\", \"rb\").read()\n",
    "print(ember.predict_sample(lgbm_model2, putty_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6252fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
